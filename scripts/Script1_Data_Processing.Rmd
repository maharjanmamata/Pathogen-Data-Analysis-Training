---
title: 'Script 1: Data Processing (Workshop Version)'
author: "Heather Amato"
date: "2025-06-22"
output: html_document
---
white for notes and in run chucnk we have to use hash sign

```{

```



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Install packages
#install.packages(c("here","tidyverse","dplyr","readxl"))

#install.packages("remotes")                        # if not already installed
#remotes::install_github("jknappe/quantitray")      # installs the package directly from GitHub

# Load libraries
library(here)
library(tidyverse)
library(dplyr)
library(quantitray)
library(readxl)

# Check current directory & set new directory if needed
here()
```

## Training Module 1. Microbiology lab results and qPCR data cleaning
In this session, we will clean and process .csv files including 

#### Read data into RStudio
We will be using the here() package which relates all file paths to the directory in which this script is stored. This makes it easier for people to collaborate across computers, as long as the folder structure is the same. We recommend storing all data on the cloud (Box or Drive) and using the desktop Box/Drive app to be able to directly access your Box/Drive folders from your local computer. For this workshop, you will be utilizing the folder on your desktop that you created with the forked GitHub repository.   
```{r read.dat}
#test<- read_csv("Users/Lenovo/Documents/GitHub/Pathogen-Data-Analysis-Training/survey_data_simulatied.csv")

# Read microbiological data
# (there are also packages you can install and load, like read_xl(), for reading .xlsx files)
microbio_df <- read_csv(here("simulated_data", "microbial_data_simulated.csv"))

# Folder path for TAC .csvs
tac_folder <- here("simulated_data", "simulated_cards")

# Read and combine all TAC .xlsx output files into tac_raw
tac_raw <- list.files(tac_folder, full.names = TRUE, pattern = "\\.xlsx$") %>%
  map_dfr(read_csv, .id = "source_file", show_col_types = FALSE)
#remove test data
rm(test)
```

## MICROBIAL DATA
#### Check micro (IDEXX) data format
```{r micro.check}
# Code provided to check structure
names(microbio_df) # variable names
summary(microbio_df) # summary of data
head(microbio_df, n=8) # view top 8 rows
unique(microbio_df$sample_id) %>% length() # number of samples
table(microbio_df$sample_type) # number of rows in dataset by type
#View(microbio_df) #it shows all chart

```

#### Clean and process microbio dataset
First we will clean the microbial results data by extracting the household id and sample type from the sample id, and calculating soil moisture content.  
```{r clean.micro}
microbio_clean <- microbio_df %>%
  mutate(
    household_id = str_extract(sample_id, "HH\\d+"), # extract household id from sample_id
    sample_type = str_extract(sample_id, "effluent|compost|produce"), # extract sample type from sample_id
    wet_soil_mass = wet_weight - plate_weight,
    dry_soil_mass = dry_weight - plate_weight,
    soil_moisture = (wet_soil_mass - dry_soil_mass) / dry_soil_mass *100 # estimate soil moisture content as percent
  ) %>%
  dplyr::select(-c(sample_id, plate_weight, wet_weight, dry_weight, wet_soil_mass, dry_soil_mass))

# Workshop task: Check your new variables,-c substraction
# Add code here to check soil_moisture (continuous) and sample_type (categorical)
table(microbio_clean$sample_type)#frequency table for categorial
summary(microbio_clean$soil_moisture)#summary of cotiunuous vars

```

#### Estimate MPN from IDEXX data
We will now use the small and large cell counts to estimate most probable number (MPN) from the IDEXX trays for each outcome variable of interest. We will also estimate the upper and lower 95% confidence limits for MPN.   
```{r mpn.task}
# Workshop task: Add MPN estimates using quantify_mpn()
# Hint: type help("quantify_mpn") in console to get information about how to use the command
microbio_clean <- microbio_clean %>%
  mutate(
    # Add total coliform and E. coli MPN estimation (with 95% confidence limits) code here
    tc_mpn = 
    tc_mpn_lo = 
    tc_mpn_hi = 

    ecoli_mpn = 
    ecoli_mpn_lo = 
    ecoli_mpn_hi = 

    ar_tc_mpn = 
    ar_tc_mpn_lo = 
    ar_tc_mpn_hi = 

    ar_ecoli_mpn = 
    ar_ecoli_mpn_lo = 
    ar_ecoli_mpn_hi = 
  )
```

```{r mpn.check}
# Check dataset
microbio_clean %>% 
  select(household_id, sample_type, tc_mpn:ar_ecoli_mpn_hi) %>% 
  head(10)
```

```{r mpn.nafix}
# Replace NA values with 0s and create detection indicators
microbio_clean <- microbio_clean %>% 
  mutate(
    across(everything(), ~replace_na(.x, 0)), # replace NAs with 0s across all variables in dataframe
    tc_detect = if_else(tc_mpn > 0, 1, 0), # set detect = 1 if mpn > 0
    ar_tc_detect = if_else(ar_tc_mpn > 0, 1, 0),
    ec_detect = if_else(ecoli_mpn > 0, 1, 0),
    ar_ec_detect = if_else(ar_ecoli_mpn > 0, 1, 0)
  )
```

#### Transform ESBL CFU results
Plate count data for ESBL-E. coli should be adjusted for moisture content and sample volume (for effluent and compost samples only), and should be log-transformed to create a normal (bell-curve) distribution for statistical analyses.  
```{r plot.cfu}
hist(microbio_clean$esbl_e_coli_cfu) # check distribution with histogram
```

```{r adjust.esbl.task}
# Workshop task: Transform esbl_e_coli_cfu values and create log-adjusted version
microbio_clean2 <- microbio_clean %>%
  mutate(
    moisture_fraction = soil_moisture / 100,
    esbl_e_coli_cfu_adj = if_else(esbl_e_coli_cfu == 0, 0.5, esbl_e_coli_cfu), # set 0s to 1/2 lower limit of detection (1 CFU)
    adjusted_esbl_cfu = case_when( # for 
      sample_type %in% c("effluent", "compost") ~ esbl_e_coli_cfu_adj / (1 - moisture_fraction) / 2,
      sample_type == "produce" ~ esbl_e_coli_cfu_adj,
      TRUE ~ NA_real_),
    
    # Add code to create new log_adjusted_esbl_cfu variable here 
    log_adjusted_esbl_cfu = 
      
  )

# Add code to check distribution of log adjusted esbl cfu variable here 
# Hint: use a histogram

```

``` {r hist.esbl.samples}
# further investigate distribution with a histogram by sample type
ggplot(microbio_clean2, aes(x = log_adjusted_esbl_cfu, fill = sample_type)) +
  geom_histogram(bins = 30, alpha = 0.6, position = "identity") +
  theme_minimal()
```

#### Transform MPN results
Next we will transform IDEXX MPN results. This process is similar to the above steps taken for ESBL E. coli, but now we will do this across multiple variables (each of the bacterial indicators).   
```{r adjust.mpn.task}
# Workshop task: Create log-transformed MPN variables
microbio_clean2 <- microbio_clean2 %>%
  mutate(
    # Add adjustments for LOD, moisture, and sample volume for compost and effluent samples
    across(c(tc_mpn, ar_tc_mpn, ecoli_mpn, ar_ecoli_mpn),
                ~ if_else(. == 0, 0.5, .), # set 0s to 1/2 lower limit of detection (1 MPN) 
                .names = "{.col}_adj")) %>%
  mutate(
    across(matches("_adj$"), # only for adjusted variables 
                ~ if_else(sample_type %in% c("compost", "effluent"), . / (1 - moisture_fraction) / 2, . / 2),
                .names = "adjusted_{.col}")) %>%
  # Add code for log10 transformation to all adjusted MPN variables here
  
  )

# Add code to check distribution of unadjusted vs. adjusted MPN variables using a histogram here

```

## TAC DATA
#### Check TAC data format
```{r tac.check}
# Check TAC data
names(tac_raw)
summary(tac_raw)
head(tac_raw)

unique(tac_raw$Sample) %>% length() # number of unique samples
unique(tac_raw$Sample[grepl("NTC", tac_raw$Sample)]) %>% length() # number of non-template controls
unique(tac_raw$Sample[grepl("NTC", tac_raw$Sample) & tac_raw$Result == "Positive"]) %>% length() # N failed NTCs
```

#### Clean TAC data
Lastly, we will clean the compiled raw TAC files by removing non-template controls (NTC) and creating new variables.  
```{r clean.tac.task}
# Workshop task: Clean TAC data and extract variables
tac_clean <- tac_raw %>%
  filter(!grepl("NTC", Sample, ignore.case = TRUE)) %>% # remove non-template controls
  
# Add code to extract household_id and sample_type and create binary detect variable here
  mutate(
    household_id = ,
    sample_type = ,
    detect = 
  )

View(tac_clean)
```

## Save final datasets
Select whatever variables you need for the analysis and save the cleaned datasets in a folder (clean_data) within the folder you created for the GitHub repository. Make sure you create the clean_data folder before running the code.  
```{r final.save.task}
# Workshop task: Save clean, compiled TAC dataset using write_csv() and here()
microbio_clean3 <- microbio_clean2 %>%
  select(household_id, sample_type, soil_moisture, esbl_ec_cfu = esbl_e_coli_cfu,
         log_adj_esbl_ecoli = log_adjusted_esbl_cfu, esbl_ecoli_detect,
         log_adj_tc_mpn = log_adjusted_tc_mpn_adj, log_adj_ec_mpn = log_adjusted_ecoli_mpn_adj,
         log_adj_ar_tc_mpn = log_adjusted_ar_tc_mpn_adj, log_adj_ar_ec_mpn = log_adjusted_ar_ecoli_mpn_adj,
         tc_detect, ec_detect, ar_tc_detect, ar_ec_detect)

write_csv(microbio_clean3, here("clean_data", "microbial_data_cleaned.csv")) # clean_data is folder in current directory

# Add code to select key variables and save cleaned TAC dataframe here

```

This is the end of the first training session!